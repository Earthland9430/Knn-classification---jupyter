{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy.random as Random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#The whole procee of this cold is to determine PCA, KNN, K-fold cross validation, and use them to get the results.\n",
    "#The file should be put on the ./Dataset for using purpose\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "class PCA:\n",
    "    def __init__(self,n_components):\n",
    "        \"\"\"\n",
    "        初始化函数\n",
    "        :param n_components: 所降低的维度\n",
    "        \"\"\"\n",
    "        self.n_components=n_components\n",
    "\n",
    "        self._mean=0\n",
    "        self._std=0\n",
    "\n",
    "    def fit(self,X):\n",
    "        \"\"\"\n",
    "\n",
    "        :param X: n个数据，m个特征\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        X = X.astype(float)\n",
    "        n = X.shape[0]\n",
    "        m = X.shape[1]\n",
    "        \n",
    "        #Normalization\n",
    "        self._mean = np.mean(X,axis=0)\n",
    "        self._std = np.std(X,axis=0)\n",
    "        X = (X - self._mean)/self._std\n",
    "        \n",
    "        Sigma = np.matmul(X.transpose(),X)/n\n",
    "\n",
    "        w,v = LA.eig(Sigma)\n",
    "        sorted_indices = np.argsort(w)\n",
    "\n",
    "        W = w[sorted_indices[:-self.n_components-1:-1]]\n",
    "        V = v[:,sorted_indices[:-self.n_components-1:-1]]\n",
    "\n",
    "\n",
    "        return np.matmul(X,V)\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self,K):\n",
    "        self.K = K\n",
    "\n",
    "    def fit(self,train_data,train_label):\n",
    "        self.train_data = train_data\n",
    "        self.train_label = train_label\n",
    "\n",
    "    def predict(self,test_data):\n",
    "        M = cdist(test_data, self.train_data, metric='euclidean', p=2)\n",
    "        ind = M.argsort(axis=1)[:,:self.K]\n",
    "        return [np.argmax(np.bincount(self.train_label[x].astype(int))) for x in ind]\n",
    "\n",
    "    def score(self,test_data,test_label):\n",
    "        return (sum(self.predict(test_data) == test_label)/test_label.shape[0])\n",
    "\n",
    "def cross_validate(d,k,data,label,k_fold=5,random_state=None):\n",
    "    if random_state != None:\n",
    "        Random.seed(random_state)\n",
    "\n",
    "    IND = []\n",
    "    for i in range(np.max(label)+1):\n",
    "        I = []\n",
    "        ind_i = np.argwhere(label == i)\n",
    "        ind_i = ind_i.squeeze(axis = 1)\n",
    "        Random.shuffle(ind_i)\n",
    "        batch_size = (ind_i.shape[0])//k_fold\n",
    "        for k_ in range(k_fold-1):\n",
    "            I.append(ind_i[k_*batch_size:(k_+1)*batch_size])\n",
    "        I.append(ind_i[(k_fold-1)*batch_size:ind_i.shape[0]])\n",
    "\n",
    "        IND.append(I)\n",
    "\n",
    "    pca = PCA(n_components=max(d))\n",
    "    data_d = pca.fit(data)\n",
    "\n",
    "    acc = np.zeros((len(d),len(k),k_fold))\n",
    "    for kk in range(k_fold):\n",
    "        data_test0 = np.concatenate([data_d[IND[ii][kk],:] for ii in range(np.max(label)+1)],axis=0)\n",
    "        label_test = np.concatenate([label[IND[ii][kk]] for ii in range(np.max(label)+1)],axis=0)\n",
    "\n",
    "        data_train0 = np.concatenate([np.concatenate([data_d[IND[ii][kk_],:] for ii in range(np.max(label)+1)],axis=0) for kk_ in set(range(k_fold)).difference(set([kk]))],axis=0)\n",
    "        label_train=np.concatenate([np.concatenate([label[IND[ii][kk_]] for ii in range(np.max(label)+1)],axis=0) for kk_ in set(range(k_fold)).difference(set([kk]))],axis=0)\n",
    "\n",
    "\n",
    "        for i,d_ in enumerate(d):\n",
    "            data_test = data_test0[:,:d_]\n",
    "            data_train = data_train0[:,:d_]\n",
    "            for j,k_ in enumerate(k):\n",
    "                knn = KNN(K=k_)\n",
    "                knn.fit(data_train,label_train)\n",
    "                acc[i,j,kk] = knn.score(data_test,label_test)\n",
    "                print('{}_fold:\\tfold{}:d={},k={},acc={}%'.format(k_fold, kk + 1,d_,k_,acc[i,j,kk]*100))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ACC = np.mean(acc,axis=2)\n",
    "    IJ = np.argwhere(ACC == np.max(ACC))\n",
    "    plt.plot(ACC,'o-')\n",
    "    plt.xlabel('d')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.legend(['k='+str(i) for i in k])\n",
    "    plt.xticks(range(len(d)), d)\n",
    "    plt.savefig('Parameters.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    return d[IJ[0][0]],k[IJ[0][1]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    # 导入数据\n",
    "    with h5py.File('Dataset/images_training.h5', 'r') as H:\n",
    "        train_data = np.copy(H['data'])\n",
    "        train_data = np.reshape(train_data/255., (-1, 28 * 28))\n",
    "    with h5py.File('Dataset/labels_training.h5', 'r') as H:\n",
    "        train_label = np.copy(H['label'])\n",
    "    with h5py.File('Dataset/images_testing.h5', 'r') as H:\n",
    "        test_data = np.copy(H['data'])\n",
    "        test_data = np.reshape(test_data/255., (-1, 28 * 28))\n",
    "    with h5py.File('Dataset/labels_testing_2000.h5', 'r') as H:\n",
    "        test_2000_label = np.copy(H['label'])\n",
    "\n",
    "\n",
    "    return (train_data,train_label,test_data,test_2000_label)\n",
    "\n",
    "\n",
    "\n",
    "train_data,train_label,test_data,test_2000_label=load_data()\n",
    "data = train_data.astype(float)\n",
    "label = train_label.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#best_d,best_k = cross_validate([1,5,10,50,100,200,28*28],[1,5,10,50,100,200],data,label,k_fold=5,random_state=0)\n",
    "\n",
    "#After doing the K-fold cross validation\n",
    "best_d=200\n",
    "best_k=5\n",
    "\n",
    "print('d={},k={}'.format(best_d,best_k))\n",
    "all = np.concatenate((train_data.astype(float),test_data),axis=0)\n",
    "pca = PCA(best_d)\n",
    "all = pca.fit(all)\n",
    "knn = KNN(best_k)\n",
    "knn.fit(all[:train_data.shape[0],:],train_label.astype(int))\n",
    "print(knn.score(all[train_data.shape[0]:train_data.shape[0]+2000,:],test_2000_label))\n",
    "\n",
    "test_results = knn.predict(all[train_data.shape[0]:,:])\n",
    "f = h5py.File(\"predicted_labels.h5\",\"w\")\n",
    "d1 = f.create_dataset(\"label\",data=test_results)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
